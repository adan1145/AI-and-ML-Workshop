{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,BaggingRegressor,ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression,Lasso,Ridge,ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold,StratifiedKFold,GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import skew,randint\n",
    "import numpy as np\n",
    "from time import time\n",
    "import preprocess\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Hyper-Parameters Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV and RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_scores(X_train,X_test,y_train,y_test,error_fn):\n",
    "    best_error = np.inf\n",
    "    best_model = None\n",
    "    models = [('RF',RandomForestRegressor(n_estimators=100, random_state=100)),\n",
    "              ('GB',GradientBoostingRegressor(n_estimators=100, random_state=100)),\n",
    "              ('ET',ExtraTreesRegressor(n_estimators=100, random_state=100)),\n",
    "              ('LR',LinearRegression()),\n",
    "              ('Lasso',Lasso(max_iter=10000,random_state=100)),\n",
    "              ('Ridge',Ridge(random_state=100)),\n",
    "              ('Elastic',ElasticNet(max_iter=10000,random_state=100))\n",
    "             ]\n",
    "    \n",
    "    for model in models:\n",
    "        model_instance = model[1]\n",
    "        model_instance.fit(X_train,y_train)\n",
    "        preds = model_instance.predict(X_test)\n",
    "        error = error_fn(y_test, preds)\n",
    "        print(\"{} error: {:.2f}\".format(model[0],error))\n",
    "        if best_error > error:\n",
    "            best_error = error\n",
    "            best_model = model_instance\n",
    "            \n",
    "    return best_model    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features4(df):\n",
    "    df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "    df[\"OverallGrade\"] = df[\"OverallQual\"] * df[\"OverallCond\"]\n",
    "    df['TotalLivArea'] = df['GrLivArea'] + df['GarageArea'] + df['LotArea']\n",
    "    \n",
    "    df[\"GrLivArea-2\"] = df[\"GrLivArea\"] ** 2\n",
    "    df[\"GrLivArea-3\"] = df[\"GrLivArea\"] ** 3\n",
    "    df[\"GrLivArea-Sq\"] = np.sqrt(df[\"GrLivArea\"])\n",
    "    df[\"GarageArea-2\"] = df[\"GarageArea\"] ** 2\n",
    "    df[\"GarageArea-3\"] = df[\"GarageArea\"] ** 3\n",
    "    df[\"GarageArea-Sq\"] = np.sqrt(df[\"GarageArea\"])\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../datasets/iowa_housing/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('../datasets/iowa_housing/test.csv', index_col='Id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_new_features4(X)\n",
    "X_test = add_new_features4(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed = preprocess.preprocess_df(X,'SalePrice',X_test,one_hot=False,scaler=RobustScaler)\n",
    "splits = pre_processed.split_df()\n",
    "X_train,X_valid,y_train,y_valid = splits['X_train'],splits['X_test'],splits['y_train'],splits['y_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report_hyper_param_search(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':[100,200,300,400,500,1500],\n",
    "           \"max_features\": randint(0,89),\n",
    "           \"min_samples_split\": randint(2, 11),\n",
    "           \"min_samples_leaf\": randint(1, 11),\n",
    "           \"subsample\":[0.6,0.7,0.75,0.8,0.9]\n",
    "         }\n",
    "\n",
    "start = time()\n",
    "randomSearch_gb = RandomizedSearchCV(GradientBoostingRegressor(warm_start=True,random_state=100),\n",
    "                                     param_distributions=params,n_iter=20,\n",
    "                                     cv=kfold,n_jobs=6)        \n",
    "randomSearch_gb.fit(X_train,y_train)\n",
    "\n",
    "print('training took {} minutes'.format((time() - start)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':[50,100,200,300],\n",
    "              'max_features': [0.5,0.7,0.9,'auto'],\n",
    "              'min_samples_split': [2,3,10],\n",
    "              'min_samples_leaf': [1,3,10],\n",
    "              \"subsample\":[0.7,0.8,0.9]}\n",
    "\n",
    "start = time()\n",
    "gridSearch_gb = GridSearchCV(GradientBoostingRegressor(warm_start=True,random_state=100),\n",
    "                                     param_grid=params,cv=kfold,n_jobs=6)        \n",
    "gridSearch_gb.fit(X_train,y_train)\n",
    "\n",
    "print('training took {} minutes'.format((time() - start)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_hyper_param_search(randomSearch_gb.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_hyper_param_search(gridSearch_gb.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(model,X_train, X_valid, y_train, y_valid,error_fn=mean_absolute_error):\n",
    "    preds = model.predict(X_valid)\n",
    "    return error_fn(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dataset(randomSearch_gb.best_estimator_,X_train, X_valid, y_train, y_valid,error_fn=mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dataset(gridSearch_gb.best_estimator_,X_train, X_valid, y_train, y_valid,error_fn=mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(randomSearch_gb.best_estimator_,pre_processed.X,pre_processed.y,cv=4)\n",
    "print(\"Cross-validation scores: {}, mean score = {}\".format(scores,scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(gridSearch_gb.best_estimator_,pre_processed.X,pre_processed.y,cv=4)\n",
    "print(\"Cross-validation scores: {}, mean score = {}\".format(scores,scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = randomSearch_gb.predict(pre_processed.X_test)\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
